{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, mean_squared_error\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['turnover'] = data['interception'] + data['fumble_lost']\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['turnover'] = data['interception'] + data['fumble_lost']\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['inside_10'] = (data['yardline_100'] < 10).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['20+_play'] = (data['yards_gained'] > 19).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['short_pass'] = (data['air_yards'] < 10).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['medium_pass'] = ((data['air_yards'] > 9)&(data['air_yards']<20)).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['deep_pass'] = (data['air_yards'] > 19).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['end_zone_target'] = (data['yardline_100'] - data['air_yards']) <= 0\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['fantasy_points'] = (\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\2001587006.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['distance_to_EZ_after_target'] = data['yardline_100'] - data['air_yards']\n"
     ]
    }
   ],
   "source": [
    "YEARS = [2018, 2019, 2020, 2021, 2022, 2023,2024]\n",
    "\n",
    "# %%\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "def calculate_seconds(row):\n",
    "    if row['qtr'] != 5:\n",
    "        return 3600 - row['game_seconds_remaining']\n",
    "    else:\n",
    "        return 600 - row['game_seconds_remaining'] + 3600\n",
    "\n",
    "\n",
    "def get_quarter_value(dataf):\n",
    "    if 'END QUARTER' in dataf['desc']:\n",
    "        return dataf['level_0']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for i in YEARS:  \n",
    "    i_data = pd.read_csv('https://github.com/nflverse/nflverse-data/releases/download/pbp/' \\\n",
    "                   'play_by_play_' + str(i) + '.csv.gz',\n",
    "                   compression= 'gzip', low_memory= False)\n",
    "\n",
    "    data_all = pd.concat([data_all,i_data])\n",
    "\n",
    "ppr = 1\n",
    "\n",
    "data = data_all.loc[data_all.season_type=='REG']\n",
    "#data = data_all.loc[(data_all.play_type.isin(['no_play','pass','run'])) & (data_all.epa.isna()==False)]\n",
    "#data.loc[data['pass']==1, 'play_type'] = 'pass'\n",
    "#data.loc[data.rush==1, 'play_type'] = 'run'\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['turnover'] = data['interception'] + data['fumble_lost']\n",
    "data = data.dropna(subset=['posteam'])\n",
    "data['inside_10'] = (data['yardline_100'] < 10).astype(int)\n",
    "data['20+_play'] = (data['yards_gained'] > 19).astype(int)\n",
    "data['short_pass'] = (data['air_yards'] < 10).astype(int)\n",
    "data['medium_pass'] = ((data['air_yards'] > 9)&(data['air_yards']<20)).astype(int)\n",
    "data['deep_pass'] = (data['air_yards'] > 19).astype(int)\n",
    "data['end_zone_target'] = (data['yardline_100'] - data['air_yards']) <= 0\n",
    "data['fantasy_points'] = (\n",
    "    data['complete_pass'] * ppr +          # 1 point per completion\n",
    "    data['touchdown'] * 6 +           # 6 points per touchdown\n",
    "    data['yards_gained'] * 0.1        # 0.1 points per yard gained\n",
    ")\n",
    "data['distance_to_EZ_after_target'] = data['yardline_100'] - data['air_yards']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_finder(home_or_away,home_total,away_total):\n",
    "    if home_or_away == 'home':\n",
    "        total = home_total\n",
    "    else:\n",
    "        total = away_total \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\1725764239.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['home_implied_total'] = abs(data['total_line'] / 2 + data['spread_line'] / 2)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\1725764239.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['away_implied_total'] = abs(data['total_line'] / 2 - data['spread_line'] / 2)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_15968\\1725764239.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['implied_posteam_total'] = [\n"
     ]
    }
   ],
   "source": [
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = data[data['two_point_attempt']==0]\n",
    "\n",
    "\n",
    "    # derive implied team total from betting market data\n",
    "    data['home_implied_total'] = abs(data['total_line'] / 2 + data['spread_line'] / 2)\n",
    "    data['away_implied_total'] = abs(data['total_line'] / 2 - data['spread_line'] / 2)\n",
    "\n",
    "    # Use list comprehension with zip for more efficient row-wise operations\n",
    "    data['implied_posteam_total'] = [\n",
    "    total_finder(has_ball, home_number, away_number)\n",
    "        for has_ball, home_number, away_number in zip(data['posteam_type'], data['home_implied_total'], data['away_implied_total'])\n",
    "]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # we only want throws to a receiver, aka plays with air yardage (no running plays, sacks, throwaways etc.)\n",
    "    throws = data[data['air_yards'].notna()]\n",
    "    # only data before the current szn\n",
    "    throws = throws[throws['season']!=2024]\n",
    "    throws = throws[throws['receiver_player_name'].notna()]\n",
    "    throws = throws[throws['pass_location'].notna()]\n",
    "\n",
    "    \n",
    "    df = throws[['receiver_player_name','receiver_player_id','posteam','pass','cp','game_id','complete_pass','inside_10','air_yards','yardline_100','ydstogo','implied_posteam_total','yards_gained','fantasy_points','pass_touchdown','down','pass_location','week','season','home_implied_total','away_implied_total','posteam_type','qb_hit','end_zone_target', 'distance_to_EZ_after_target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiver_player_name</th>\n",
       "      <th>receiver_player_id</th>\n",
       "      <th>posteam</th>\n",
       "      <th>pass</th>\n",
       "      <th>cp</th>\n",
       "      <th>game_id</th>\n",
       "      <th>complete_pass</th>\n",
       "      <th>inside_10</th>\n",
       "      <th>air_yards</th>\n",
       "      <th>yardline_100</th>\n",
       "      <th>...</th>\n",
       "      <th>down</th>\n",
       "      <th>pass_location</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>home_implied_total</th>\n",
       "      <th>away_implied_total</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>qb_hit</th>\n",
       "      <th>end_zone_target</th>\n",
       "      <th>distance_to_EZ_after_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.Jones</td>\n",
       "      <td>00-0027944</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713305</td>\n",
       "      <td>2018_01_ATL_PHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C.Ridley</td>\n",
       "      <td>00-0034837</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766752</td>\n",
       "      <td>2018_01_ATL_PHI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D.Freeman</td>\n",
       "      <td>00-0031285</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875661</td>\n",
       "      <td>2018_01_ATL_PHI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J.Jones</td>\n",
       "      <td>00-0027944</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349099</td>\n",
       "      <td>2018_01_ATL_PHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D.Freeman</td>\n",
       "      <td>00-0031285</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610173</td>\n",
       "      <td>2018_01_ATL_PHI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>22.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263168</th>\n",
       "      <td>M.Evans</td>\n",
       "      <td>00-0031408</td>\n",
       "      <td>TB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743172</td>\n",
       "      <td>2023_18_TB_CAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>18</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.75</td>\n",
       "      <td>20.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263169</th>\n",
       "      <td>T.Palmer</td>\n",
       "      <td>00-0039052</td>\n",
       "      <td>TB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.356356</td>\n",
       "      <td>2023_18_TB_CAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>right</td>\n",
       "      <td>18</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.75</td>\n",
       "      <td>20.75</td>\n",
       "      <td>away</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263175</th>\n",
       "      <td>T.Marshall</td>\n",
       "      <td>00-0036955</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752642</td>\n",
       "      <td>2023_18_TB_CAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>18</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.75</td>\n",
       "      <td>20.75</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263178</th>\n",
       "      <td>D.Chark</td>\n",
       "      <td>00-0034777</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777339</td>\n",
       "      <td>2023_18_TB_CAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>18</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.75</td>\n",
       "      <td>20.75</td>\n",
       "      <td>home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263187</th>\n",
       "      <td>C.Godwin</td>\n",
       "      <td>00-0033921</td>\n",
       "      <td>TB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545205</td>\n",
       "      <td>2023_18_TB_CAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>18</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.75</td>\n",
       "      <td>20.75</td>\n",
       "      <td>away</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104462 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       receiver_player_name receiver_player_id posteam  pass        cp  \\\n",
       "2                   J.Jones         00-0027944     ATL     1  0.713305   \n",
       "5                  C.Ridley         00-0034837     ATL     1  0.766752   \n",
       "6                 D.Freeman         00-0031285     ATL     1  0.875661   \n",
       "7                   J.Jones         00-0027944     ATL     1  0.349099   \n",
       "10                D.Freeman         00-0031285     ATL     1  0.610173   \n",
       "...                     ...                ...     ...   ...       ...   \n",
       "263168              M.Evans         00-0031408      TB     1  0.743172   \n",
       "263169             T.Palmer         00-0039052      TB     1  0.356356   \n",
       "263175           T.Marshall         00-0036955     CAR     1  0.752642   \n",
       "263178              D.Chark         00-0034777     CAR     1  0.777339   \n",
       "263187             C.Godwin         00-0033921      TB     1  0.545205   \n",
       "\n",
       "                game_id  complete_pass  inside_10  air_yards  yardline_100  \\\n",
       "2       2018_01_ATL_PHI            1.0          0        8.0          80.0   \n",
       "5       2018_01_ATL_PHI            0.0          0        4.0          39.0   \n",
       "6       2018_01_ATL_PHI            0.0          0       -3.0          39.0   \n",
       "7       2018_01_ATL_PHI            1.0          0       24.0          39.0   \n",
       "10      2018_01_ATL_PHI            0.0          1        1.0           1.0   \n",
       "...                 ...            ...        ...        ...           ...   \n",
       "263168   2023_18_TB_CAR            1.0          0        5.0          21.0   \n",
       "263169   2023_18_TB_CAR            0.0          0       13.0          15.0   \n",
       "263175   2023_18_TB_CAR            1.0          0        5.0          59.0   \n",
       "263178   2023_18_TB_CAR            1.0          0        4.0          52.0   \n",
       "263187   2023_18_TB_CAR            1.0          0       11.0          36.0   \n",
       "\n",
       "        ...  down  pass_location  week  season  home_implied_total  \\\n",
       "2       ...   1.0          right     1    2018               22.75   \n",
       "5       ...   1.0          right     1    2018               22.75   \n",
       "6       ...   2.0           left     1    2018               22.75   \n",
       "7       ...   3.0           left     1    2018               22.75   \n",
       "10      ...   3.0          right     1    2018               22.75   \n",
       "...     ...   ...            ...   ...     ...                 ...   \n",
       "263168  ...   1.0          right    18    2023               15.75   \n",
       "263169  ...   2.0          right    18    2023               15.75   \n",
       "263175  ...   2.0           left    18    2023               15.75   \n",
       "263178  ...   1.0          right    18    2023               15.75   \n",
       "263187  ...   3.0          right    18    2023               15.75   \n",
       "\n",
       "        away_implied_total posteam_type  qb_hit  end_zone_target  \\\n",
       "2                    21.75         away     0.0            False   \n",
       "5                    21.75         away     0.0            False   \n",
       "6                    21.75         away     0.0            False   \n",
       "7                    21.75         away     0.0            False   \n",
       "10                   21.75         away     0.0             True   \n",
       "...                    ...          ...     ...              ...   \n",
       "263168               20.75         away     0.0            False   \n",
       "263169               20.75         away     1.0            False   \n",
       "263175               20.75         home     0.0            False   \n",
       "263178               20.75         home     0.0            False   \n",
       "263187               20.75         away     0.0            False   \n",
       "\n",
       "        distance_to_EZ_after_target  \n",
       "2                              72.0  \n",
       "5                              35.0  \n",
       "6                              42.0  \n",
       "7                              15.0  \n",
       "10                              0.0  \n",
       "...                             ...  \n",
       "263168                         16.0  \n",
       "263169                          2.0  \n",
       "263175                         54.0  \n",
       "263178                         48.0  \n",
       "263187                         25.0  \n",
       "\n",
       "[104462 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}\n",
      "RMSE: 0.1806\n",
      "ROC-AUC Score: 0.9282\n",
      "\n",
      "Probability Calibration Check:\n",
      "\n",
      "Probability range 0.0-0.1 (n=18402):\n",
      "Average predicted: 0.011\n",
      "Actual observed: 0.010\n",
      "\n",
      "Probability range 0.1-0.2 (n=603):\n",
      "Average predicted: 0.139\n",
      "Actual observed: 0.149\n",
      "\n",
      "Probability range 0.2-0.3 (n=531):\n",
      "Average predicted: 0.258\n",
      "Actual observed: 0.249\n",
      "\n",
      "Probability range 0.3-0.4 (n=746):\n",
      "Average predicted: 0.343\n",
      "Actual observed: 0.342\n",
      "\n",
      "Probability range 0.4-0.5 (n=378):\n",
      "Average predicted: 0.443\n",
      "Actual observed: 0.466\n",
      "\n",
      "Probability range 0.5-0.6 (n=196):\n",
      "Average predicted: 0.562\n",
      "Actual observed: 0.531\n",
      "\n",
      "Probability range 0.6-0.7 (n=37):\n",
      "Average predicted: 0.615\n",
      "Actual observed: 0.541\n",
      "\n",
      "Feature Importance:\n",
      "                       Feature  Importance\n",
      "7  distance_to_EZ_after_target    0.628491\n",
      "1                 yardline_100    0.137423\n",
      "6              end_zone_target    0.108043\n",
      "0                    air_yards    0.038680\n",
      "5                       qb_hit    0.022743\n",
      "2                      ydstogo    0.019546\n",
      "8         pass_location_middle    0.013728\n",
      "3                         down    0.013180\n",
      "9          pass_location_right    0.009232\n",
      "4                       season    0.008934\n",
      "\n",
      "Example Play Touchdown Probability: 0.5%\n",
      "\n",
      "Top factors influencing this prediction:\n",
      "distance_to_EZ_after_target: 50 (importance: 0.628)\n",
      "yardline_100: 70 (importance: 0.137)\n",
      "end_zone_target: 0 (importance: 0.108)\n",
      "air_yards: 20 (importance: 0.039)\n",
      "qb_hit: 0 (importance: 0.023)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load and prepare data (same as before)\n",
    "predictors = [\n",
    "    'air_yards', 'yardline_100', 'ydstogo',\n",
    "    'down', 'pass_location', 'season', 'qb_hit', 'end_zone_target', 'distance_to_EZ_after_target'\n",
    "]\n",
    "X = df[predictors]\n",
    "y = df['pass_touchdown']\n",
    "\n",
    "# Convert categorical variables\n",
    "X = pd.get_dummies(X, columns=['pass_location'], drop_first=True)\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create XGBoost regression model with probability-focused objective\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:logistic',  # This constrains outputs to [0,1]\n",
    "    eval_metric=['rmse', 'logloss'],  # Track both regression and classification metrics\n",
    ")\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "# Grid search with both MSE and ROC-AUC scoring\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=['neg_mean_squared_error', 'roc_auc'],\n",
    "    refit='neg_mean_squared_error',  # Choose MSE as primary metric\n",
    "    cv=5\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "touchdown_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = touchdown_model.predict(X_test)\n",
    "\n",
    "# Evaluate both regression and classification metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Evaluation:\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Check calibration across probability ranges\n",
    "prob_ranges = np.linspace(0, 1, 11)\n",
    "print(\"\\nProbability Calibration Check:\")\n",
    "for i in range(len(prob_ranges)-1):\n",
    "    mask = (y_pred >= prob_ranges[i]) & (y_pred < prob_ranges[i+1])\n",
    "    if mask.any():\n",
    "        avg_pred_prob = y_pred[mask].mean()\n",
    "        actual_prob = y_test[mask].mean()\n",
    "        n_samples = mask.sum()\n",
    "        print(f\"\\nProbability range {prob_ranges[i]:.1f}-{prob_ranges[i+1]:.1f} (n={n_samples}):\")\n",
    "        print(f\"Average predicted: {avg_pred_prob:.3f}\")\n",
    "        print(f\"Actual observed: {actual_prob:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "importance = touchdown_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Example prediction function\n",
    "def predict_touchdown_probability(model, play_data):\n",
    "    \"\"\"\n",
    "    Make touchdown probability predictions for new plays.\n",
    "    \"\"\"\n",
    "    # Ensure play_data has same preprocessing as training data\n",
    "    play_data = pd.get_dummies(play_data, columns=['pass_location'], drop_first=True)\n",
    "    \n",
    "    # Add any missing columns from training data\n",
    "    for col in model.feature_names_in_:\n",
    "        if col not in play_data.columns:\n",
    "            play_data[col] = 0\n",
    "            \n",
    "    # Reorder columns to match training data\n",
    "    play_data = play_data[model.feature_names_in_]\n",
    "    \n",
    "    # Get predictions and ensure they're in [0,1]\n",
    "    probabilities = model.predict(play_data)\n",
    "    probabilities = np.clip(probabilities, 0, 1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "# Print top factors influencing this prediction\n",
    "def explain_prediction(model, play_data, feature_importance_df):\n",
    "    \"\"\"Explain what factors most influenced a specific prediction\"\"\"\n",
    "    # Get the top 5 most important features\n",
    "    top_features = feature_importance_df.head()\n",
    "    \n",
    "    print(\"\\nTop factors influencing this prediction:\")\n",
    "    for _, row in top_features.iterrows():\n",
    "        feature = row['Feature']\n",
    "        if feature in play_data.columns:\n",
    "            value = play_data[feature].iloc[0]\n",
    "            print(f\"{feature}: {value} (importance: {row['Importance']:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('touchdown_model.pkl', 'wb') as file:\n",
    "    pickle.dump(touchdown_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
