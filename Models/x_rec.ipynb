{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['turnover'] = data['interception'] + data['fumble_lost']\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['turnover'] = data['interception'] + data['fumble_lost']\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['inside_10'] = (data['yardline_100'] < 10).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['20+_play'] = (data['yards_gained'] > 19).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['short_pass'] = (data['air_yards'] < 10).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['medium_pass'] = ((data['air_yards'] > 9)&(data['air_yards']<20)).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['deep_pass'] = (data['air_yards'] > 19).astype(int)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['end_zone_target'] = (data['yardline_100'] - data['air_yards']) <= 0\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['fantasy_points'] = (\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\1346690318.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['distance_to_EZ_after_target'] = data['yardline_100'] - data['air_yards']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Assuming `model` is your trained model\n",
    "\n",
    "\n",
    "# %%\n",
    "YEARS = [2018, 2019, 2020, 2021, 2022, 2023,2024]\n",
    "\n",
    "# %%\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "def calculate_seconds(row):\n",
    "    if row['qtr'] != 5:\n",
    "        return 3600 - row['game_seconds_remaining']\n",
    "    else:\n",
    "        return 600 - row['game_seconds_remaining'] + 3600\n",
    "\n",
    "\n",
    "def get_quarter_value(dataf):\n",
    "    if 'END QUARTER' in dataf['desc']:\n",
    "        return dataf['level_0']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for i in YEARS:  \n",
    "    i_data = pd.read_csv('https://github.com/nflverse/nflverse-data/releases/download/pbp/' \\\n",
    "                   'play_by_play_' + str(i) + '.csv.gz',\n",
    "                   compression= 'gzip', low_memory= False)\n",
    "\n",
    "    data_all = pd.concat([data_all,i_data])\n",
    "\n",
    "ppr = 1\n",
    "\n",
    "data = data_all.loc[data_all.season_type=='REG']\n",
    "#data = data_all.loc[(data_all.play_type.isin(['no_play','pass','run'])) & (data_all.epa.isna()==False)]\n",
    "#data.loc[data['pass']==1, 'play_type'] = 'pass'\n",
    "#data.loc[data.rush==1, 'play_type'] = 'run'\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['turnover'] = data['interception'] + data['fumble_lost']\n",
    "data = data.dropna(subset=['posteam'])\n",
    "data['inside_10'] = (data['yardline_100'] < 10).astype(int)\n",
    "data['20+_play'] = (data['yards_gained'] > 19).astype(int)\n",
    "data['short_pass'] = (data['air_yards'] < 10).astype(int)\n",
    "data['medium_pass'] = ((data['air_yards'] > 9)&(data['air_yards']<20)).astype(int)\n",
    "data['deep_pass'] = (data['air_yards'] > 19).astype(int)\n",
    "data['end_zone_target'] = (data['yardline_100'] - data['air_yards']) <= 0\n",
    "data['fantasy_points'] = (\n",
    "    data['complete_pass'] * ppr +          # 1 point per completion\n",
    "    data['touchdown'] * 6 +           # 6 points per touchdown\n",
    "    data['yards_gained'] * 0.1        # 0.1 points per yard gained\n",
    ")\n",
    "data['distance_to_EZ_after_target'] = data['yardline_100'] - data['air_yards']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "2021    45049\n",
       "2023    44877\n",
       "2024    44686\n",
       "2022    44558\n",
       "2019    43012\n",
       "2020    43004\n",
       "2018    42697\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['season'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_finder(home_or_away,home_total,away_total):\n",
    "    if home_or_away == 'home':\n",
    "        total = home_total\n",
    "    else:\n",
    "        total = away_total \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\532167629.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['home_implied_total'] = abs(data['total_line'] / 2 + data['spread_line'] / 2)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\532167629.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['away_implied_total'] = abs(data['total_line'] / 2 - data['spread_line'] / 2)\n",
      "C:\\Users\\src15\\AppData\\Local\\Temp\\ipykernel_18104\\532167629.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['implied_posteam_total'] = [\n"
     ]
    }
   ],
   "source": [
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = data[data['two_point_attempt']==0]\n",
    "\n",
    "\n",
    "    # derive implied team total from betting market data\n",
    "    data['home_implied_total'] = abs(data['total_line'] / 2 + data['spread_line'] / 2)\n",
    "    data['away_implied_total'] = abs(data['total_line'] / 2 - data['spread_line'] / 2)\n",
    "\n",
    "    # Use list comprehension with zip for more efficient row-wise operations\n",
    "    data['implied_posteam_total'] = [\n",
    "    total_finder(has_ball, home_number, away_number)\n",
    "        for has_ball, home_number, away_number in zip(data['posteam_type'], data['home_implied_total'], data['away_implied_total'])\n",
    "    ]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # we only want throws to a receiver, aka plays with air yardage (no running plays, sacks, throwaways etc.)\n",
    "    throws = data[data['air_yards'].notna()]\n",
    "    # only data before the current szn\n",
    "    throws = throws[throws['season']!=2024]\n",
    "    throws = throws[throws['receiver_player_name'].notna()]\n",
    "    throws = throws[throws['pass_location'].notna()]\n",
    "\n",
    "    \n",
    "    df = throws[['receiver_player_name','receiver_player_id','posteam','pass','cp','game_id','complete_pass','inside_10','air_yards','yardline_100','ydstogo','implied_posteam_total','yards_gained','fantasy_points','pass_touchdown','down','pass_location','week','season','home_implied_total','away_implied_total','posteam_type','qb_hit','end_zone_target', 'distance_to_EZ_after_target']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yardage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Mean Squared Error: 85.43\n",
      "R^2 Score: 0.12\n",
      "Feature Importance:\n",
      "                       Feature  Importance\n",
      "0                    air_yards    0.372470\n",
      "1                 yardline_100    0.154565\n",
      "4                       qb_hit    0.108111\n",
      "5              end_zone_target    0.103794\n",
      "6  distance_to_EZ_after_target    0.091725\n",
      "7         pass_location_middle    0.084814\n",
      "3                         down    0.048900\n",
      "2                      ydstogo    0.021486\n",
      "8          pass_location_right    0.014135\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "# data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "predictors = [\n",
    "    'air_yards', 'yardline_100', 'ydstogo',\n",
    "    'down', 'pass_location', 'qb_hit', 'end_zone_target', 'distance_to_EZ_after_target'\n",
    "]\n",
    "X = df[predictors]\n",
    "y = df['yards_gained']\n",
    "\n",
    "# Convert categorical variables (if needed)\n",
    "X = pd.get_dummies(X, columns=['pass_location'], drop_first=True)\n",
    "\n",
    "# Handle missing values if any\n",
    "X.fillna(X.mean(), inplace=True)  # Example for filling with mean\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "yardage_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = yardage_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "importance = yardage_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importance\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rec_yardage_model.pkl', 'wb') as file:\n",
    "    pickle.dump(yardage_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
